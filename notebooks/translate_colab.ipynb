{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "translate-colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Machine-Learning-Tokyo/Seq2Seq-Workshop/blob/master/notebooks/translate_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "sg68qiQrofYP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Machine Translation\n",
        "A sequence-to-sequence model is a model that takes a sequence of items and outputs another sequence of items using two networks that are trained end-to-end. This is perfect for machine translation since input sequences are directly related to output sequences. We will looking at preparing a dataset for Machine Translation task and implementing a seq2seq model. We will be using the parallel corpus available from [here](ftp://ftp.monash.edu/pub/nihongo/examples.utf.gz) \n",
        "\n",
        "### Concepts covered here:\n",
        "- Encoder-Decoder architecture: We will be using a encoder to encode input sequences from one language in a latent space and use the encoding to generate words in the target language one token at a time. The encoder and the decoder are an RNNs. \n",
        "\n",
        "- Attention: We will be looking at the attention mechanism described in [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf). We will explore the theory, the intuition behind it and how to move from theory and intuition to implementation."
      ]
    },
    {
      "metadata": {
        "id": "K1HzG6z-ofYV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from pathlib import Path\n",
        "import re,string\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U3BP_G6DofYi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MButr8N2ofYo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = Path('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pwynv43oofYz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will need to download the translation corpus and install a tokenizer for Japanese text."
      ]
    },
    {
      "metadata": {
        "id": "U61Hl7vSofY1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#get corpus\n",
        "#!wget ftp://ftp.monash.edu/pub/nihongo/examples.utf.gz\n",
        "#decompress it and move it to data folder\n",
        "#!gunzip examples.utf.gz\n",
        "#!mv examples.utf data/\n",
        "#install dependencies for mecab tokenizer\n",
        "#!sudo apt install swig\n",
        "#!sudo apt install mecab\n",
        "#!sudo apt install libmecab-dev\n",
        "#!sudo apt install mecab-ipadic-utf8\n",
        "#!sudo pip3 install mecab-python3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Twukc-eCofY7",
        "colab_type": "code",
        "outputId": "3fcfbf43-93de-40cf-d546-d30ef26687d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "corpus = (path/'examples.utf').open().readlines()\n",
        "corpus[:5]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A: ムーリエルは２０歳になりました。\\tMuiriel is 20 now.#ID=1282_4707\\n',\n",
              " 'B: は 二十歳(はたち){２０歳} になる[01]{になりました}\\n',\n",
              " 'A: すぐに戻ります。\\tI will be back soon.#ID=1284_4709\\n',\n",
              " 'B: 直ぐに{すぐに} 戻る{戻ります}\\n',\n",
              " 'A: すぐに諦めて昼寝をするかも知れない。\\tI may give up soon and just nap instead.#ID=1300_4727\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "nTkXpahLofZG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_corpus(corpus_path):\n",
        "    corpus = corpus_path.open().readlines()\n",
        "    en,ja = [],[]\n",
        "    pat = r'#ID.+\\n'\n",
        "    for c in corpus:\n",
        "        if 'A: ' in c:\n",
        "            clean_c = c.replace('A: ','')\n",
        "            res = re.search(pat,clean_c)\n",
        "            clean_c = clean_c.replace(res.group(0),'').split('\\t')\n",
        "            ja.append(clean_c[0])\n",
        "            en.append(clean_c[1])\n",
        "    return en,ja"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "opZ65gotofZR",
        "colab_type": "code",
        "outputId": "d66cacf1-30aa-4ee6-d3b7-80fea20755b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "en, ja = make_corpus(path/'examples.utf')\n",
        "en[:2],ja[:2]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Muiriel is 20 now.', 'I will be back soon.'],\n",
              " ['ムーリエルは２０歳になりました。', 'すぐに戻ります。'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "iR594C8GofZZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import MeCab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3HyMAMlhofZn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tagger = MeCab.Tagger('-Owakati')\n",
        "\n",
        "def ja_tokenizer(text):\n",
        "    result = tagger.parse(text)\n",
        "    words = result.split()\n",
        "    if len(words) ==0: return []\n",
        "    if words[-1] == '\\n':return words[:-1]\n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yNT8-DYNofZx",
        "colab_type": "code",
        "outputId": "92f09d1d-9009-44d4-fac3-cb19241c3aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "ja_tokenizer(ja[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ムーリエル', 'は', '２', '０', '歳', 'に', 'なり', 'まし', 'た', '。']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "YGocE3VGofZ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.symbols import ORTH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LXDkYBV9ofZ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "en_tok = spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sr3MSI5nofaC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def en_tokenizer(text):\n",
        "    text = text.lower()\n",
        "    return [t.text for t in en_tok.tokenizer(text)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N7peSCuvofaH",
        "colab_type": "code",
        "outputId": "ffa041c4-58f1-439f-964b-ea3fb65a10f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "en_tokenizer(en[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['muiriel', 'is', '20', 'now', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "QF2BEH-2ofaQ",
        "colab_type": "code",
        "outputId": "9bdef6e7-6a9a-4cdd-e7fc-b9b01f846ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "en_toks = [en_tokenizer(text) for text in en]\n",
        "ja_toks = [ja_tokenizer(text) for text in ja]\n",
        "en_toks[:2], ja_toks[:2]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['muiriel', 'is', '20', 'now', '.'],\n",
              "  ['i', 'will', 'be', 'back', 'soon', '.']],\n",
              " [['ムーリエル', 'は', '２', '０', '歳', 'に', 'なり', 'まし', 'た', '。'],\n",
              "  ['すぐ', 'に', '戻り', 'ます', '。']])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "xrqazu4HofaY",
        "colab_type": "code",
        "outputId": "b3f273a1-fb91-4508-e7c2-ec0309773107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(en_toks), len(ja_toks)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(149785, 149785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "Wpfm_Ej7ofap",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter,defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1NJyFRxpofax",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def numericalize_tok(tokens, max_vocab=50000, min_freq=3, unk_tok=\"xxunk\", pad_tok=\"xxpad\", bos_tok=\"xxbos\", eos_tok=\"xxeos\"):\n",
        "    if isinstance(tokens, str):\n",
        "        raise ValueError(\"Expected to receive a list of tokens. Received a string instead\")\n",
        "    if isinstance(tokens[0], list):\n",
        "        tokens = [p for o in tokens for p in o]\n",
        "    freq = Counter(tokens)\n",
        "    int2tok = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
        "    unk_id = 3\n",
        "    int2tok.insert(0, bos_tok)\n",
        "    int2tok.insert(1, pad_tok)\n",
        "    int2tok.insert(2, eos_tok)\n",
        "    int2tok.insert(unk_id, unk_tok)\n",
        "    tok2int = defaultdict(lambda:unk_id, {v:k for k,v in enumerate(int2tok)})\n",
        "    return int2tok, tok2int"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CK8GKEHBofa8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "int2j,j2int = numericalize_tok(ja_toks)\n",
        "int2en,en2int = numericalize_tok(en_toks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5_dgvcf8ofbD",
        "colab_type": "code",
        "outputId": "0e01f52f-19dd-473b-9c8d-7dc6a6351c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(int2j), len(int2en)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12677, 9290)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "yoxPO1bsofbK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vM1PpGJrofbP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pickle.dump(int2j,(path/'int2j.pkl').open('wb'))\n",
        "pickle.dump(int2en,(path/'int2en.pkl').open('wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XpnnzchKofbU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "int2j = pickle.load((path/'int2j.pkl').open('rb'))\n",
        "int2en = pickle.load((path/'int2en.pkl').open('rb'))\n",
        "j2int = defaultdict(lambda:3, {v:k for k,v in enumerate(int2j)})\n",
        "en2int = defaultdict(lambda:3, {v:k for k,v in enumerate(int2en)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jhw-qW2kofbZ",
        "colab_type": "code",
        "outputId": "41c623a2-1458-4be9-81d9-3a0a6d2e857f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(int2j), len(int2en)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12677, 9290)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "PmPrYkw9ofbo",
        "colab_type": "code",
        "outputId": "17b6c7f5-7b3f-4818-9a75-1843f616b42b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        }
      },
      "cell_type": "code",
      "source": [
        "j_ids = np.array([[0]+[j2int[o] for o in sent]+[2] for sent in ja_toks])\n",
        "en_ids = np.array([[0]+[en2int[o] for o in sent]+[2] for sent in en_toks])\n",
        "len(j_ids),len(en_ids), j_ids[10],en_ids[10]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(149785,\n",
              " 149785,\n",
              " [0,\n",
              "  48,\n",
              "  6,\n",
              "  4891,\n",
              "  5,\n",
              "  109,\n",
              "  11,\n",
              "  143,\n",
              "  10,\n",
              "  83,\n",
              "  8,\n",
              "  57,\n",
              "  86,\n",
              "  1798,\n",
              "  7,\n",
              "  2146,\n",
              "  232,\n",
              "  255,\n",
              "  47,\n",
              "  36,\n",
              "  4,\n",
              "  2],\n",
              " [0, 114, 2251, 107, 38, 97, 85, 2649, 77, 28, 356, 4, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "8C3vDdseofbw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KP5VS6Fbofb2",
        "colab_type": "code",
        "outputId": "1f82de5a-2f0b-4184-a2b0-8c4f17b1566f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "trn_keep = np.random.rand(len(en_ids))>0.1\n",
        "en_trn,j_trn = en_ids[trn_keep],j_ids[trn_keep]\n",
        "en_val,j_val = en_ids[~trn_keep],j_ids[~trn_keep]\n",
        "len(en_trn),len(en_val)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(134774, 15011)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "E3X7oW0cofb9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.autograd.variable import Variable\n",
        "from torch.utils.data import Dataset,DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F9RhzGOYofcB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy import array as A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mdg0frrJofcF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Seq2SeqDataset(Dataset):\n",
        "    def __init__(self, x, y): self.x,self.y = x,y\n",
        "    def __getitem__(self, idx): return A(self.x[idx]), A(self.y[idx])\n",
        "    def __len__(self): return len(self.x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bW9NpORdofcI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trn_ds = Seq2SeqDataset(en_trn,j_trn)\n",
        "val_ds = Seq2SeqDataset(en_val,j_val)\n",
        "\n",
        "bs = 120\n",
        "\n",
        "trn_dl = DataLoader(trn_ds,batch_size=bs,shuffle=True)\n",
        "val_dl = DataLoader(val_ds,batch_size=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "al6bVtbYofcL",
        "colab_type": "code",
        "outputId": "261d0a68-7958-4566-e7a1-bc62db74ad24",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x, y = next(iter(val_dl))\n",
        "x.size(), y.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([120, 25]), torch.Size([120, 25]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "mwU9mMMJofcR",
        "colab_type": "code",
        "outputId": "5cd0135c-76fd-45f5-9ae5-b86793a12e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "lQKNaYmSofcY",
        "colab_type": "code",
        "outputId": "a4a5b62f-503b-4acb-e155-b72f8a364906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "enlen_90 = int(np.percentile([len(o) for o in en_ids], 99))\n",
        "jalen_90 = int(np.percentile([len(o) for o in j_ids], 99))\n",
        "enlen_90,jalen_90"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 29)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "LEwZeKxIofch",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "j_ids = pad_sequences(j_ids, maxlen=29, dtype='int32', padding='post', truncating='post', value=1)\n",
        "en_ids = pad_sequences(en_ids, maxlen=25, dtype='int32', padding='post', truncating='post', value=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w1_NIPvGrG1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ceae3e88-956c-448e-a791-effff0b0b0b2"
      },
      "cell_type": "code",
      "source": [
        "trn_keep = np.random.rand(len(en_ids))>0.1\n",
        "en_trn,j_trn = en_ids[trn_keep],j_ids[trn_keep]\n",
        "en_val,j_val = en_ids[~trn_keep],j_ids[~trn_keep]\n",
        "len(en_trn),len(en_val)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(134746, 15039)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "pwrMeKyErK3S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trn_ds = Seq2SeqDataset(en_trn,j_trn)\n",
        "val_ds = Seq2SeqDataset(en_val,j_val)\n",
        "\n",
        "bs = 120\n",
        "\n",
        "trn_dl = DataLoader(trn_ds,batch_size=bs,shuffle=True)\n",
        "val_dl = DataLoader(val_ds,batch_size=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gNxWk9MirNDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b2f1a9c6-3178-4cdb-bd82-c501dec9d34b"
      },
      "cell_type": "code",
      "source": [
        "x, y = next(iter(val_dl))\n",
        "x.size(), y.size()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([120, 25]), torch.Size([120, 29]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "1EAQQbnUofck",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## load fasttext vectors\n",
        "#code from here:https://github.com/facebookresearch/fastText/blob/master/docs/crawl-vectors.md\n",
        "import io\n",
        "def load_vectors(fname):\n",
        "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    header = fin.readline().split()\n",
        "    n, d = int(header[0]), int(header[1])\n",
        "    data = {}\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        data[tokens[0]] = np.array(tokens[1:], dtype=float)\n",
        "    return data, int(n), int(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "s764uzHPofco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "a514f24d-a0e9-4fe1-c69c-4222f058ba1c"
      },
      "cell_type": "code",
      "source": [
        "# get word vectors\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ja.300.vec.gz\n",
        "!unzip wiki-news-300d-1M.vec.zip\n",
        "!gunzip cc.ja.300.vec.gz\n",
        "!mv wiki-news-300d-1M.vec data/\n",
        "!mv cc.ja.300.vec data/"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-15 09:27:27--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.22.166, 104.20.6.166, 2606:4700:10::6814:6a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.22.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  30.1MB/s    in 22s     \n",
            "\n",
            "2019-03-15 09:27:49 (29.4 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n",
            "--2019-03-15 09:27:51--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ja.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.22.166, 104.20.6.166, 2606:4700:10::6814:6a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.22.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1279641604 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ja.300.vec.gz’\n",
            "\n",
            "cc.ja.300.vec.gz    100%[===================>]   1.19G  30.1MB/s    in 41s     \n",
            "\n",
            "2019-03-15 09:28:32 (29.9 MB/s) - ‘cc.ja.300.vec.gz’ saved [1279641604/1279641604]\n",
            "\n",
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j5-nC9FFofct",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "en_vecs,_,dim_en_vec = load_vectors('data/wiki-news-300d-1M.vec')\n",
        "j_vecs,_,dim_j_vec = load_vectors('data/cc.ja.300.vec')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7HT5m4aRofcx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_emb(vecs, itos, em_sz):\n",
        "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
        "    wgts = emb.weight.data\n",
        "    miss = []\n",
        "    for i,w in enumerate(itos):\n",
        "        try: wgts[i] = torch.from_numpy(vecs[w])\n",
        "        except: miss.append(w)\n",
        "    print('Number of unknowns in data: {}'.format(len(miss)))\n",
        "    return emb\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yoCxoafyofc3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def V(tensor,req_grad=True):\n",
        "    if torch.cuda.is_available():return Variable(tensor.cuda())\n",
        "    else: return Variable(tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ilfz1MLDofc6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RNN Visualization"
      ]
    },
    {
      "metadata": {
        "id": "cgnGnKnttPA2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[RNN Visualization](http://jalammar.github.io/images/RNN_1.mp4)"
      ]
    },
    {
      "metadata": {
        "id": "o8zV-dwhofc_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Seq2Seq Architecture\n",
        "> ...a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. \n",
        "\n",
        "[Sutskever et al., 2014](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)"
      ]
    },
    {
      "metadata": {
        "id": "XavH76_gofdC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://lilianweng.github.io/lil-log/assets/images/encoder-decoder-example.png)\n",
        "\n",
        "Image:[from here](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)"
      ]
    },
    {
      "metadata": {
        "id": "gzPOwPQbofdD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,int2en,int2j,em_sz,j_vecs=None,en_vecs=None,nh=128,out_sl=25,dropf=1,nl=2):\n",
        "        super().__init__()\n",
        "        #encoder\n",
        "        self.nl,self.nh,self.em_sz,self.out_sl = nl,nh,em_sz,out_sl\n",
        "        self.emb_enc = create_emb(en_vecs,int2en,dim_en_vec)\n",
        "        self.emb_drop = nn.Dropout(0.15*dropf)\n",
        "        self.encoder = nn.GRU(dim_en_vec,nh,num_layers=nl,dropout=0.25*dropf, bidirectional=True)\n",
        "        #decoder\n",
        "        self.emb_dec = create_emb(j_vecs,int2j,dim_j_vec)\n",
        "        self.decoder = nn.GRU(dim_en_vec,nh*2,num_layers=nl,dropout=0.25*dropf)\n",
        "        self.out_drop = nn.Dropout(0.35*dropf)\n",
        "        self.out = nn.Linear(nh*2,len(int2j))\n",
        "    \n",
        "    def forward(self,inp,y=None):\n",
        "        sl, bs = inp.size()\n",
        "        emb_in = self.emb_drop(self.emb_enc(inp))\n",
        "        h_n = self.initHidden(bs)\n",
        "        enc_out, h_n = self.encoder(emb_in,h_n)\n",
        "        h_n = h_n.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(self.nl,bs,-1)\n",
        "        \n",
        "        dec_inp = V(torch.zeros(bs).long())\n",
        "        res = []\n",
        "        for i in range(self.out_sl):\n",
        "            dec_emb = self.emb_dec(dec_inp)\n",
        "            outp,h_n = self.decoder(dec_emb.unsqueeze(0),h_n)\n",
        "            outp = F.log_softmax(self.out(self.out_drop(outp[0])),dim=-1)\n",
        "            res.append(outp)\n",
        "            dec_inp = outp.data.max(1)[1]\n",
        "            if (dec_inp==1).all(): break\n",
        "        return torch.stack(res)\n",
        "        \n",
        "    def initHidden(self,bs):\n",
        "        return V(torch.zeros([self.nl*2,bs,self.nh]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X-ICi6rIofdH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Why Bidirectional Encoder\n",
        "> Finally, we found that reversing the order of the words in all source sentences (butnot target sentences) improved the LSTM’s performance markedly, because doing so introduced many short term dependencies between the source and the targetsentence which made the optimization problem easier.\n",
        "\n",
        "[Sutskever et al., 2014](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)\n",
        "\n",
        "Input and output sequences may not directly map to each other so preserving information from both passes of the input sequence will help learn how tokens relate to each other. For example in a translation task, subject and object can be in opposite positions depending on the language structure."
      ]
    },
    {
      "metadata": {
        "id": "zMiSmH-1ofdI",
        "colab_type": "code",
        "outputId": "9b69bb4c-768f-49f9-ada7-236795765bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "cell_type": "code",
      "source": [
        "seq2seq = Seq2Seq(int2en,int2j,dim_en_vec,en_vecs=en_vecs,j_vecs=j_vecs)\n",
        "seq2seq.cuda()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unknowns in data: 100\n",
            "Number of unknowns in data: 45\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (emb_enc): Embedding(9290, 300, padding_idx=1)\n",
              "  (emb_drop): Dropout(p=0.15)\n",
              "  (encoder): GRU(300, 128, num_layers=2, dropout=0.25, bidirectional=True)\n",
              "  (emb_dec): Embedding(12677, 300, padding_idx=1)\n",
              "  (decoder): GRU(300, 256, num_layers=2, dropout=0.25)\n",
              "  (out_drop): Dropout(p=0.35)\n",
              "  (out): Linear(in_features=256, out_features=12677, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "HM4wZkm4ofdN",
        "colab_type": "code",
        "outputId": "d5c67bcb-b561-4281-9d1d-2264b52ae1e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "out = seq2seq(V(x.transpose(1,0).long()))\n",
        "out.size()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([25, 120, 12677])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "iBFRG6KquIrA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loss Function: We will use Cross Entropy Loss as we are trying to classify ot the correct words. Cross entropy loss can be simplified to: \n",
        "\n",
        "`cross_entropy = sum(-log(y_pred) for y_pred in y_preds)`\n",
        "\n",
        "where `y_pred` is the likelihood of the target class predicted by the model. This is a good loss function for classification because if the likelihood of the correct class is low, the loss value goes up and if it is high, the loss value goes down."
      ]
    },
    {
      "metadata": {
        "id": "iVZr0DKXofdg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def seq2seq_loss(input, target):\n",
        "    sl,bs = target.size()\n",
        "    sl_in,bs_in,nc = input.size()\n",
        "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
        "    input = input[:sl]\n",
        "    return F.cross_entropy(input.view(-1,nc), target.view(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ZiCZXSLofdi",
        "colab_type": "code",
        "outputId": "b62f1dfe-4b20-48a9-f2b1-d2968bb23a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "seq2seq_loss(out,V(y.transpose(1,0).long()))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9.4514, device='cuda:0', grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "sgZkBJpmofdu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def step(x, y, epoch, m, crit, opt, clip=None):\n",
        "    output = m(x, y)\n",
        "    if isinstance(output,tuple): output = output[0]\n",
        "    opt.zero_grad()\n",
        "    loss = crit(output, y)\n",
        "    loss.backward()\n",
        "    if clip:\n",
        "        nn.utils.clip_grad_norm_(m.parameters(), clip)\n",
        "    opt.step()\n",
        "    return loss.data.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U9etuKhJofdx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BfqS-K9hofd0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(trn_dl,val_dl,model,crit,opt,epochs=10,clip=None):\n",
        "    for epoch in range(epochs):\n",
        "        loss_val = loss_trn = 0\n",
        "        with tqdm(total=len(trn_dl)) as pbar:\n",
        "            model.train()\n",
        "            for i, ds in enumerate(trn_dl):\n",
        "                x, y = ds\n",
        "                #if isinstance(x,tuple): x = x[0]\n",
        "                x, y = x.transpose(1,0), y.transpose(1,0)\n",
        "                loss = step(V(x.long()),V(y.long()),epoch,model,crit,opt)\n",
        "                loss_trn += loss\n",
        "                pbar.update()\n",
        "        model.eval()\n",
        "        for i, ds in enumerate(val_dl):\n",
        "            with torch.no_grad():\n",
        "                x, y = ds\n",
        "                #if isinstance(x,tuple): x = x[0]\n",
        "                x, y = x.transpose(1,0), y.transpose(1,0)\n",
        "                out = model(V(x.long()))\n",
        "                if isinstance(out,tuple): out = out[0]\n",
        "                loss_val+= crit(out, V(y.long()))\n",
        "                #loss_val +=loss\n",
        "        print(f'Epoch: {epoch} trn loss: {loss_trn/len(trn_dl)} val loss: {loss_val/len(val_dl)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TjyftC-xofd4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zR4cgUcuofd9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = optim.Adam(seq2seq.parameters(),lr=3e-3,betas=(0.7,0.8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "jHRr5_-eofeE",
        "colab_type": "code",
        "outputId": "42e4d3bf-ee1b-408c-9601-ea8db2944cbb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(trn_dl,val_dl,seq2seq,seq2seq_loss,opt,epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [02:40<00:00,  7.02it/s]\n",
            "  0%|          | 1/1124 [00:00<03:05,  6.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 trn loss: 4.750732962983359 val loss: 4.082951068878174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [02:52<00:00,  6.51it/s]\n",
            "  0%|          | 1/1124 [00:00<03:11,  5.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 trn loss: 3.5997307712073003 val loss: 3.3246185779571533\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [02:55<00:00,  6.39it/s]\n",
            "  0%|          | 1/1124 [00:00<03:04,  6.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2 trn loss: 3.1077632744965604 val loss: 3.4751904010772705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [02:57<00:00,  6.34it/s]\n",
            "  0%|          | 1/1124 [00:00<02:50,  6.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3 trn loss: 2.8518904808153036 val loss: 3.94274640083313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [02:58<00:00,  6.30it/s]\n",
            "  0%|          | 1/1124 [00:00<03:06,  6.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4 trn loss: 2.7045018161743135 val loss: 2.766321897506714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [02:58<00:00,  6.29it/s]\n",
            "  0%|          | 1/1124 [00:00<03:06,  6.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5 trn loss: 2.5743112220458713 val loss: 2.752124071121216\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [02:58<00:00,  6.28it/s]\n",
            "  0%|          | 1/1124 [00:00<03:04,  6.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6 trn loss: 2.5332621384769998 val loss: 2.935807228088379\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [02:59<00:00,  6.27it/s]\n",
            "  0%|          | 1/1124 [00:00<03:03,  6.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7 trn loss: 2.500852593323514 val loss: 3.133931875228882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [02:59<00:00,  6.99it/s]\n",
            "  0%|          | 1/1124 [00:00<03:04,  6.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8 trn loss: 2.458315055141245 val loss: 2.8610451221466064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [02:59<00:00,  6.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9 trn loss: 2.456163497369909 val loss: 3.016350269317627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EXi-KaFMofeI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def produce_out(val_dl, model,int2en,int2j,interval=(20,30)):\n",
        "    model.eval()\n",
        "    x,y = next(iter(val_dl))\n",
        "    x, y = x.transpose(1,0), y.transpose(1,0)\n",
        "    probs = seq2seq(V(x.long()))\n",
        "    if isinstance(probs,tuple): probs = probs[0] \n",
        "    preds = A(probs.max(2)[1])\n",
        "    for i in range(interval[0],interval[1]):\n",
        "        print(' '.join([int2en[o] for o in x[:,i] if o not in [0,1,2]]))\n",
        "        print(''.join([int2j[o] for o in y[:,i] if o not in [0,1,2]]))\n",
        "        print(''.join([int2j[o] for o in preds[:,i] if o not in [0,1,2]]))\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "lQeV6Kr3ofeM",
        "colab_type": "code",
        "outputId": "87f704fe-f2de-4a20-ea53-c46e8e56b2c1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "produce_out(trn_dl,seq2seq,int2en,int2j)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my grandfather tells us about old things .\n",
            "祖父は昔の話をしてくれます。\n",
            "私は私のののををて。\n",
            "\n",
            "if it had not been for your help , we might have failed .\n",
            "もしあなたの援助がなければ、私たちは失敗していたかもしれない。\n",
            "もしののがなかったら、私私失敗失敗失敗たうううう\n",
            "\n",
            "there was a long interval before he answered .\n",
            "彼が答えるまでに長い間があった。\n",
            "彼ははのののががた。\n",
            "\n",
            "i was scolded by my mother for being lazy .\n",
            "怠けていて母にしかられた。\n",
            "私は母にれれれれたた\n",
            "\n",
            "while she was running after the naughty boy , one of her shoes came off .\n",
            "いたずらっ子を追いかけているうちに彼女の靴が片方脱げた。\n",
            "彼女はが彼女て、、彼女彼女のににてて。。\n",
            "\n",
            "they contributed money to the red cross .\n",
            "彼らは赤十字にお金を寄付した。\n",
            "彼らはお金をためををたた。\n",
            "\n",
            "i 've just oiled the wheels .\n",
            "車輪には油を注したばかりだ。\n",
            "私はをををたた。。\n",
            "\n",
            "there are such shops about .\n",
            "そのような店はあちらこちらにある。\n",
            "そのににはははががて。。\n",
            "\n",
            "give me a knife to cut this string with .\n",
            "この紐を切るためのナイフを貸してください。\n",
            "このをををををててて。\n",
            "\n",
            "he is bound to pass the test .\n",
            "彼はきっと試験に合格する。\n",
            "彼は試験ににするするだろ。\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UzHLtvebofeQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(seq2seq.state_dict(),open(path/'translate_seq2seq.pth','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2hUfDEl5ofeT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seq2seq.load_state_dict(torch.load(path/'translate_seq2seq.pth', map_location=lambda storage, loc: storage))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qgdyPPy0ofeU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Seq2Seq w/ Attention\n",
        "A critical and apparent disadvantage of this fixed-length context vector design is incapability of remembering long sentences. Often it has forgotten the first part once it completes processing the whole input. The attention mechanism was born [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf) to resolve this problem."
      ]
    },
    {
      "metadata": {
        "id": "98fQ-RqEofeV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Given the following vectors:\n",
        "\\begin{align}\n",
        "\\boldsymbol{x} = \\{x_1,x_2,x_3,\\ldots,x_n\\} \\\\\n",
        "\\boldsymbol{y} = \\{y_1,y_2,y_3,\\ldots,y_m\\} \\\\\n",
        "\\end{align}\n",
        "The hidden state from the Bidir encoder is given by:\n",
        "\\begin{align}\n",
        "\\boldsymbol{h}_i = [\\overrightarrow{\\boldsymbol{h}}_i^\\top; \\overleftarrow{\\boldsymbol{h}}_i^\\top]^\\top, i=1,\\dots,n \\\\\n",
        "\\end{align}\n",
        "\n",
        "The hidden state from the decoder at time $t$ is given by:  $s_t$\n",
        "\n",
        "The score for at time $t$:\n",
        "\n",
        "\\begin{aligned}\n",
        "\\text{score}(\\boldsymbol{s}_t, \\boldsymbol{h}_i) = \\mathbf{v}_a^\\top \\tanh(\\mathbf{W}_a[\\boldsymbol{s}_t; \\boldsymbol{h}_i])\n",
        "\\end{aligned}\n",
        "\n",
        "where both $v_a$ and $W_a$ are weight matrices to be learned in the alignment model.\n",
        "\n",
        "\\begin{aligned}\n",
        "\\mathbf{c}_t &= \\sum_{i=1}^n \\alpha_{t,i} \\boldsymbol{h}_i & \\small{\\text{; Context vector for output }y_t}\\\\\n",
        "\\alpha_{t,i} &= \\text{align}(y_t, x_i) & \\small{\\text{; How well two words }y_t\\text{ and }x_i\\text{ are aligned.}}\\\\\n",
        "&= \\frac{\\exp(\\text{score}(\\boldsymbol{s}_{t-1}, \\boldsymbol{h}_i))}{\\sum_{i'=1}^n \\exp(\\text{score}(\\boldsymbol{s}_{t-1}, \\boldsymbol{h}_{i'}))} & \\small{\\text{; Softmax of some predefined alignment score.}}.\n",
        "\\end{aligned}\n",
        "\n",
        "Equations borrowed from [here](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "m214-pzUvqKk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[Attention Visualization](http://jalammar.github.io/images/attention_process.mp4)"
      ]
    },
    {
      "metadata": {
        "id": "0unSAxc9ofeh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math,random\n",
        "\n",
        "def rand_t(*sz): return torch.randn(sz)/math.sqrt(sz[0])\n",
        "def rand_p(*sz): return nn.Parameter(rand_t(*sz))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0mswRcrEofej",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Seq2SeqAttention(nn.Module):\n",
        "    def __init__(self,int2en,int2j,em_sz,j_vecs=None,en_vecs=None,nh=128,out_sl=25,dropf=1,nl=2):\n",
        "        super().__init__()\n",
        "        #encoder\n",
        "        self.nl,self.nh,self.em_sz,self.out_sl = nl,nh,em_sz,out_sl\n",
        "        self.emb_enc = create_emb(en_vecs,int2en,dim_en_vec)\n",
        "        self.emb_drop = nn.Dropout(0.15*dropf)\n",
        "        self.encoder = nn.GRU(dim_en_vec,nh,num_layers=nl,dropout=0.25*dropf, bidirectional=True)\n",
        "        #decoder\n",
        "        self.emb_dec = create_emb(j_vecs,int2j,dim_j_vec)\n",
        "        self.decoder = nn.GRU(dim_en_vec,nh*2,num_layers=nl,dropout=0.25*dropf)\n",
        "        self.out_drop = nn.Dropout(0.35*dropf)\n",
        "        self.out = nn.Linear(nh*2,len(int2j))\n",
        "        #attention layer\n",
        "        self.W1 = rand_p(nh*2, nh*2) #parameter\n",
        "        self.l2 = nn.Linear(nh*2, nh*2)\n",
        "        self.l3 = nn.Linear(dim_en_vec+nh*2, dim_en_vec)\n",
        "        self.V = rand_p(nh*2) #parameter\n",
        "    \n",
        "    def forward(self,inp,y=None):\n",
        "        sl, bs = inp.size()\n",
        "        emb_in = self.emb_drop(self.emb_enc(inp))\n",
        "        h_n = self.initHidden(bs)\n",
        "        enc_out, h_n = self.encoder(emb_in,h_n)\n",
        "        h_n = h_n.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(self.nl,bs,-1)\n",
        "        \n",
        "        dec_inp = V(torch.zeros(bs).long())\n",
        "        res,attns = [], []\n",
        "        #multiply by parameter\n",
        "        w1e = enc_out @ self.W1\n",
        "        for i in range(self.out_sl):\n",
        "            #linear layer \n",
        "            w2h = self.l2(h_n[-1])\n",
        "            #non-linear activation to calculate score\n",
        "            u = torch.tanh(w1e + w2h)\n",
        "            #softmax to make them into probs\n",
        "            a = F.softmax(u @ self.V, 0)\n",
        "            attns.append(a)\n",
        "            #multiply each vector by scores and then add them up\n",
        "            Xa = (a.unsqueeze(2) * enc_out).sum(0)\n",
        "            dec_emb = self.emb_dec(dec_inp)\n",
        "            #linear layer to reduce dimensions\n",
        "            wgt_enc = self.l3(torch.cat([dec_emb, Xa], 1))\n",
        "            outp,h_n = self.decoder(wgt_enc.unsqueeze(0),h_n)\n",
        "            outp = F.log_softmax(self.out(self.out_drop(outp[0])),dim=-1)\n",
        "            res.append(outp)\n",
        "            dec_inp = outp.data.max(1)[1]\n",
        "            if (random.random() > 0.5) and y is not None: dec_inp=y[i] \n",
        "            if (dec_inp==1).all(): break\n",
        "        return torch.stack(res),attns\n",
        "        \n",
        "    def initHidden(self,bs):\n",
        "        return V(torch.zeros([self.nl*2,bs,self.nh]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HmHhbq8rofek",
        "colab_type": "code",
        "outputId": "f9718d2d-1775-487e-ae8f-7aaf4894e1d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "cell_type": "code",
      "source": [
        "seq2seq = Seq2SeqAttention(int2en,int2j,dim_en_vec,en_vecs=en_vecs,j_vecs=j_vecs)\n",
        "seq2seq.cuda()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unknowns in data: 100\n",
            "Number of unknowns in data: 45\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqAttention(\n",
              "  (emb_enc): Embedding(9290, 300, padding_idx=1)\n",
              "  (emb_drop): Dropout(p=0.15)\n",
              "  (encoder): GRU(300, 128, num_layers=2, dropout=0.25, bidirectional=True)\n",
              "  (emb_dec): Embedding(12677, 300, padding_idx=1)\n",
              "  (decoder): GRU(300, 256, num_layers=2, dropout=0.25)\n",
              "  (out_drop): Dropout(p=0.35)\n",
              "  (out): Linear(in_features=256, out_features=12677, bias=True)\n",
              "  (l2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (l3): Linear(in_features=556, out_features=300, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "l7puJEQ7ofer",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = optim.Adam(seq2seq.parameters(),lr=3e-3,betas=(0.7,0.8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "ynhTylNpofe7",
        "colab_type": "code",
        "outputId": "30d427fc-9b26-4366-fc10-051eb0b85684",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(trn_dl,val_dl,seq2seq,seq2seq_loss,opt,epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [03:21<00:00,  6.28it/s]\n",
            "  0%|          | 1/1124 [00:00<03:27,  5.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 trn loss: 2.797933133683595 val loss: 4.138897895812988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [03:26<00:00,  6.24it/s]\n",
            "  0%|          | 1/1124 [00:00<03:32,  5.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 trn loss: 2.16145394790215 val loss: 2.8873095512390137\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [03:26<00:00,  6.17it/s]\n",
            "  0%|          | 1/1124 [00:00<03:29,  5.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2 trn loss: 2.0703822573733075 val loss: 3.0309219360351562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [03:26<00:00,  6.07it/s]\n",
            "  0%|          | 1/1124 [00:00<03:28,  5.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3 trn loss: 2.07098806148322 val loss: 2.844566822052002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [03:26<00:00,  6.07it/s]\n",
            "  0%|          | 1/1124 [00:00<03:28,  5.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4 trn loss: 2.088127380906475 val loss: 2.8696582317352295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [03:26<00:00,  6.26it/s]\n",
            "  0%|          | 1/1124 [00:00<03:29,  5.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5 trn loss: 2.093448414603162 val loss: 2.7895729541778564\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [03:26<00:00,  6.12it/s]\n",
            "  0%|          | 1/1124 [00:00<03:29,  5.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6 trn loss: 2.1055155513125383 val loss: 2.9072670936584473\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [03:26<00:00,  5.45it/s]\n",
            "  0%|          | 1/1124 [00:00<03:30,  5.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7 trn loss: 2.11192792569191 val loss: 2.7808303833007812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [03:26<00:00,  6.23it/s]\n",
            "  0%|          | 1/1124 [00:00<03:29,  5.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8 trn loss: 2.116793169139543 val loss: 2.8389084339141846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1124/1124 [03:26<00:00,  6.13it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9 trn loss: 2.1336968614325404 val loss: 2.8806753158569336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "pTCVj6mZoffA",
        "colab_type": "code",
        "outputId": "89ade8ce-18e9-4bcd-b878-0f32aaa3fabd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "produce_out(trn_dl,seq2seq,int2en,int2j)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i 've been to osaka on business .\n",
            "仕事で大阪まで行ってきた。\n",
            "私は東京に行っていた。\n",
            "\n",
            "she has no sense of the beautiful .\n",
            "彼女は美に対するセンスを持っていない。\n",
            "彼女はその美しいががない。\n",
            "\n",
            "please give him my best regards .\n",
            "彼によろしくお伝え下さい。\n",
            "私におて下さい。\n",
            "\n",
            "she is working night and day .\n",
            "彼女は昼も夜も働いている。\n",
            "彼女は一日中にてている。\n",
            "\n",
            "words fail right when you need them .\n",
            "いよいよという時に言葉が出ない。\n",
            "あなたの言葉にはている。\n",
            "\n",
            "she excels her class in music .\n",
            "彼女は音楽ではクラスの誰よりも優れている。\n",
            "彼女はクラスの音楽が好きだ。\n",
            "\n",
            "he was brilliant in the morning sun .\n",
            "彼が朝日を受けて光り輝いていた。\n",
            "彼は太陽のにににた。\n",
            "\n",
            "he searched the room for the lost key .\n",
            "彼はなくした鍵を捜して部屋を調べた。\n",
            "彼は部屋を部屋ををた。\n",
            "\n",
            "a sprain like this should heal within a week or so .\n",
            "この程度の捻挫なら、１週間程で治るでしょう。\n",
            "こののははににににはている。\n",
            "\n",
            "rules in connection with staff selection are set as follows .\n",
            "職員の選考に関する規則を次のように定める。\n",
            "次ののははののである。\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vxl-CyUYoffD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(seq2seq.state_dict(),open(path/'translate_seq2seq_attention.pth','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MbRIfxtJoffF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seq2seq.load_state_dict(torch.load(path/'translate_seq2seq_attention.pth', map_location=lambda storage, loc: storage))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uOrfhaCGoffG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out, atts = seq2seq(x.long().cuda())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tlqy3VhVoffJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GgbCdh-DoffN",
        "colab_type": "code",
        "outputId": "6c44d1ba-2e41-409e-f313-5b2388b5bd0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "torch.stack(atts).size()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([25, 120, 25])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "metadata": {
        "id": "utuQs5KHoffV",
        "colab_type": "code",
        "outputId": "7b0cda70-0f1f-4264-ed44-be42fedb1ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "plt.matshow(torch.stack(atts)[:,2,:].detach().cpu().numpy())"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f118b8f0780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqoAAAKjCAYAAADVii2iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 396x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 341,
              "height": 337
            }
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "PH94uE0L4MGr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}