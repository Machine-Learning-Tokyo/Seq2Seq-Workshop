{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re,string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A: ムーリエルは２０歳になりました。\\tMuiriel is 20 now.#ID=1282_4707\\n',\n",
       " 'B: は 二十歳(はたち){２０歳} になる[01]{になりました}\\n',\n",
       " 'A: すぐに戻ります。\\tI will be back soon.#ID=1284_4709\\n',\n",
       " 'B: 直ぐに{すぐに} 戻る{戻ります}\\n',\n",
       " 'A: すぐに諦めて昼寝をするかも知れない。\\tI may give up soon and just nap instead.#ID=1300_4727\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = (path/'examples.utf').open().readlines()\n",
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corpus(corpus_path):\n",
    "    corpus = corpus_path.open().readlines()\n",
    "    en,ja = [],[]\n",
    "    pat = r'#ID.+\\n'\n",
    "    for c in corpus:\n",
    "        if 'A: ' in c:\n",
    "            clean_c = c.replace('A: ','')\n",
    "            res = re.search(pat,clean_c)\n",
    "            clean_c = clean_c.replace(res.group(0),'').split('\\t')\n",
    "            ja.append(clean_c[0])\n",
    "            en.append(clean_c[1])\n",
    "    return en,ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Muiriel is 20 now.', 'I will be back soon.'],\n",
       " ['ムーリエルは２０歳になりました。', 'すぐに戻ります。'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en, ja = make_corpus(path/'examples.utf')\n",
    "en[:2],ja[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = MeCab.Tagger('-Owakati')\n",
    "\n",
    "def ja_tokenizer(text):\n",
    "    result = tagger.parse(text)\n",
    "    words = result.split()\n",
    "    if len(words) ==0: return []\n",
    "    if words[-1] == '\\n':return words[:-1]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ムーリエル', 'は', '２', '０', '歳', 'に', 'なり', 'まし', 'た', '。']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_tokenizer(ja[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.symbols import ORTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def en_tokenizer(text):\n",
    "    text = text.lower()\n",
    "    return [t.text for t in en_tok.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['muiriel', 'is', '20', 'now', '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tokenizer(en[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['muiriel', 'is', '20', 'now', '.'],\n",
       "  ['i', 'will', 'be', 'back', 'soon', '.']],\n",
       " [['ムーリエル', 'は', '２', '０', '歳', 'に', 'なり', 'まし', 'た', '。'],\n",
       "  ['すぐ', 'に', '戻り', 'ます', '。']])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_toks = [en_tokenizer(text) for text in en]\n",
    "ja_toks = [ja_tokenizer(text) for text in ja]\n",
    "en_toks[:2], ja_toks[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149786, 149786)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_toks), len(ja_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter,defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_tok(tokens, max_vocab=50000, min_freq=0, unk_tok=\"_unk_\", pad_tok=\"_pad_\", bos_tok=\"_bos_\", eos_tok=\"_eos_\"):\n",
    "    if isinstance(tokens, str):\n",
    "        raise ValueError(\"Expected to receive a list of tokens. Received a string instead\")\n",
    "    if isinstance(tokens[0], list):\n",
    "        tokens = [p for o in tokens for p in o]\n",
    "    freq = Counter(tokens)\n",
    "    int2tok = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
    "    unk_id = 3\n",
    "    int2tok.insert(0, bos_tok)\n",
    "    int2tok.insert(1, pad_tok)\n",
    "    int2tok.insert(2, eos_tok)\n",
    "    int2tok.insert(unk_id, unk_tok)\n",
    "    tok2int = defaultdict(lambda:unk_id, {v:k for k,v in enumerate(int2tok)})\n",
    "    return int2tok, tok2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2j,j2int = numericalize_tok(ja_toks)\n",
    "int2en,en2int = numericalize_tok(en_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31813, 21393)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(int2j), len(int2en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(int2j,(path/'int2j.pkl').open('wb'))\n",
    "pickle.dump(int2en,(path/'int2en.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2j = pickle.load((path/'int2j.pkl').open('rb'))\n",
    "int2en = pickle.load((path/'int2en.pkl').open('rb'))\n",
    "j2int = defaultdict(lambda:3, {v:k for k,v in enumerate(int2j)})\n",
    "en2int = defaultdict(lambda:3, {v:k for k,v in enumerate(int2en)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31813, 21393)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(int2j), len(int2en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149786,\n",
       " 149786,\n",
       " [0,\n",
       "  48,\n",
       "  6,\n",
       "  4891,\n",
       "  5,\n",
       "  109,\n",
       "  11,\n",
       "  143,\n",
       "  10,\n",
       "  83,\n",
       "  8,\n",
       "  57,\n",
       "  86,\n",
       "  1798,\n",
       "  7,\n",
       "  2146,\n",
       "  232,\n",
       "  255,\n",
       "  47,\n",
       "  36,\n",
       "  4,\n",
       "  2],\n",
       " [0, 114, 2251, 107, 38, 97, 85, 2649, 77, 28, 356, 4, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_ids = np.array([[0]+[j2int[o] for o in sent]+[2] for sent in ja_toks])\n",
    "en_ids = np.array([[0]+[en2int[o] for o in sent]+[2] for sent in en_toks])\n",
    "len(j_ids),len(en_ids), j_ids[10],en_ids[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134775, 15011)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "trn_keep = np.random.rand(len(en_ids))>0.1\n",
    "en_trn,j_trn = en_ids[trn_keep],j_ids[trn_keep]\n",
    "en_val,j_val = en_ids[~trn_keep],j_ids[~trn_keep]\n",
    "len(en_trn),len(en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd.variable import Variable\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __getitem__(self, idx): return A(self.x[idx]), A(self.y[idx])\n",
    "    def __len__(self): return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = Seq2SeqDataset(en_trn,j_trn)\n",
    "val_ds = Seq2SeqDataset(en_val,j_val)\n",
    "\n",
    "bs = 120\n",
    "\n",
    "trn_dl = DataLoader(trn_ds,batch_size=bs,shuffle=True)\n",
    "val_dl = DataLoader(val_ds,batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([120, 57]), torch.Size([120, 70]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(val_dl))\n",
    "x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 70)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(o) for o in en_ids), max(len(o) for o in j_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_ids = pad_sequences(j_ids, maxlen=70, dtype='int32', padding='post', truncating='post', value=1)\n",
    "en_ids = pad_sequences(en_ids, maxlen=57, dtype='int32', padding='post', truncating='post', value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load fasttext vectors\n",
    "import io\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    header = fin.readline().split()\n",
    "    n, d = int(header[0]), int(header[1])\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.array(tokens[1:], dtype=float)\n",
    "    return data, n, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get word vectors\n",
    "#!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
    "#!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ja.300.vec.gz\n",
    "#!unzip wiki-news-300d-1M.vec.zip\n",
    "#!gunzip cc.ja.300.vec.gz\n",
    "#!mv wiki-news-300d-1M.vec ../data/\n",
    "#!mv cc.ja.300.vec ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecs,_,dim_en_vec = load_vectors('../data/wiki-news-300d-1M.vec')\n",
    "j_vecs,_,dim_j_vec = load_vectors('../data/cc.ja.300.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w])\n",
    "        except: miss.append(w)\n",
    "    print('Number of unknowns in data: {}'.format(len(miss)))\n",
    "    return emb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def V(tensor,req_grad=True):\n",
    "    if torch.cuda.is_available():return Variable(tensor.cuda())\n",
    "    else: return Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,en_vecs,int2en,j_vecs,int2j,em_sz,nh=128,out_sl=25,dropf=1,nl=2):\n",
    "        super().__init__()\n",
    "        #encoder\n",
    "        self.nl,self.nh,self.em_sz,self.out_sl = nl,nh,em_sz,out_sl\n",
    "        self.emb_enc = create_emb(en_vecs,int2en,dim_en_vec)\n",
    "        self.emb_drop = nn.Dropout(0.15*dropf)\n",
    "        self.encoder = nn.GRU(dim_en_vec,nh,num_layers=nl,dropout=0.25*dropf, bidirectional=True)\n",
    "        #decoder\n",
    "        self.emb_dec = create_emb(j_vecs,int2j,dim_j_vec)\n",
    "        self.decoder = nn.GRU(dim_en_vec,nh*2,num_layers=nl,dropout=0.25*dropf)\n",
    "        self.out_drop = nn.Dropout(0.35*dropf)\n",
    "        self.out = nn.Linear(nh*2,len(int2j))\n",
    "    \n",
    "    def forward(self,inp,y=None):\n",
    "        sl, bs = inp.size()\n",
    "        emb_in = self.emb_drop(self.emb_enc(inp))\n",
    "        h_n = self.initHidden(bs)\n",
    "        enc_out, h_n = self.encoder(emb_in,h_n)\n",
    "        h_n = h_n.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(self.nl,bs,-1)\n",
    "        \n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            dec_emb = self.emb_dec(dec_inp)\n",
    "            outp,h_n = self.decoder(dec_emb.unsqueeze(0),h_n)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = outp.data.max(1)[1]\n",
    "            if (dec_inp==1).all(): break\n",
    "        return torch.stack(res)\n",
    "        \n",
    "    def initHidden(self,bs):\n",
    "        return V(torch.zeros([self.nl*2,bs,self.nh]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unknowns in data: 974\n",
      "Number of unknowns in data: 492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (emb_enc): Embedding(21393, 300, padding_idx=1)\n",
       "  (emb_drop): Dropout(p=0.15)\n",
       "  (encoder): GRU(300, 128, num_layers=2, dropout=0.25, bidirectional=True)\n",
       "  (emb_dec): Embedding(31813, 300, padding_idx=1)\n",
       "  (decoder): GRU(300, 256, num_layers=2, dropout=0.25)\n",
       "  (out_drop): Dropout(p=0.35)\n",
       "  (out): Linear(in_features=256, out_features=31813, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq = Seq2Seq(en_vecs,int2en,j_vecs,int2j,dim_en_vec)\n",
    "seq2seq.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 120, 31813])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = seq2seq(V(x.transpose(1,0).long()))\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(input, target):\n",
    "    sl,bs = target.size()\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    input = input[:sl]\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.3639, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_loss(out,V(y.transpose(1,0).long()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x, y, epoch, m, crit, opt, clip=None):\n",
    "    output = m(x, y)\n",
    "    opt.zero_grad()\n",
    "    loss = crit(output, y)\n",
    "    loss.backward()\n",
    "    if clip:\n",
    "        nn.utils.clip_grad_norm_(m.parameters(), clip)\n",
    "    opt.step()\n",
    "    return loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trn_dl,val_dl,model,crit,opt,epochs=10,clip=None):\n",
    "    for epoch in range(epochs):\n",
    "        loss_val = loss_trn = 0\n",
    "        with tqdm(total=len(trn_dl)) as pbar:\n",
    "            model.train()\n",
    "            for i, ds in enumerate(trn_dl):\n",
    "                x, y = ds\n",
    "                x, y = x.transpose(1,0), y.transpose(1,0)\n",
    "                loss = step(V(x.long()),V(y.long()),epoch,model,crit,opt)\n",
    "                loss_trn += loss\n",
    "                pbar.update()\n",
    "        model.eval()\n",
    "        for i, ds in enumerate(val_dl):\n",
    "            with torch.no_grad():\n",
    "                x, y = ds\n",
    "                x, y = x.transpose(1,0), y.transpose(1,0)\n",
    "                out = model(V(x.long()))\n",
    "                loss_val+= crit(out, V(y.long()))\n",
    "                #loss_val +=loss\n",
    "        print(f'Epoch: {epoch} trn loss: {loss_trn/len(trn_dl)} val loss: {loss_val/len(val_dl)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(seq2seq.parameters(),lr=3e-3,betas=(0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2106/2106 [04:27<00:00,  7.90it/s]\n",
      "  0%|          | 1/2106 [00:00<04:41,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 trn loss: 5.353990527639362 val loss: 4.235739231109619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2106/2106 [04:29<00:00,  7.89it/s]\n",
      "  0%|          | 1/2106 [00:00<04:42,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 trn loss: 5.3160017594086595 val loss: 4.451933860778809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2106/2106 [04:34<00:00,  7.67it/s]\n",
      "  0%|          | 1/2106 [00:00<04:48,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 trn loss: 5.301374776637339 val loss: 3.4797050952911377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2106/2106 [04:33<00:00,  7.75it/s]\n",
      "  0%|          | 1/2106 [00:00<04:41,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 trn loss: 5.27146399123037 val loss: 3.608781576156616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2106/2106 [04:31<00:00,  7.58it/s]\n",
      "  0%|          | 1/2106 [00:00<04:43,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 trn loss: 5.246326666385473 val loss: 3.31687068939209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2106/2106 [04:31<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 trn loss: 5.223315402879561 val loss: 3.676764488220215\n"
     ]
    }
   ],
   "source": [
    "train(trn_dl,val_dl,seq2seq,seq2seq_loss,opt,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_out(val_dl, model,int2en,int2j,interval=(20,30)):\n",
    "    model.eval()\n",
    "    x,y = next(iter(val_dl))\n",
    "    probs = seq2seq(V(x.long()))\n",
    "    preds = A(probs.max(2)[1])\n",
    "    for i in range(interval[0],interval[1]):\n",
    "        print(' '.join([int2en[o] for o in x[i,:] if o not in [0,1,2]]))\n",
    "        print(''.join([int2j[o] for o in y[i,:] if o not in [0,1,2]]))\n",
    "        print(''.join([int2j[o] for o in preds[:,i] if o not in [0,1,2]]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the contents of the four registers are preserved by the called subroutine .\n",
      "4つのレジスタは、呼び出された関数側が保存する。\n",
      "このははのににに。。。\n",
      "\n",
      "that was when i was in the first year at high school , so 17 years have passed since then .\n",
      "それが高1の時だから17年が経ちました。\n",
      "彼女ののて。。\n",
      "\n",
      "the siren sounded an emergency .\n",
      "サイレンが急変を知らせました。\n",
      "どうぞは。\n",
      "\n",
      "the daughter was irritated with her mother , who always broke her promises .\n",
      "娘はいつも、約束を守らない母親に苛立っていた。\n",
      "彼ははが。。。\n",
      "\n",
      "however the disciples awoke to that danger .\n",
      "しかし、使徒たちはその危険に気付いた。\n",
      "そのののののの、、、、、、、、。。。\n",
      "\n",
      "no consideration is paid to people who are sensitive to chemicals .\n",
      "化学物質に敏感な人々への配慮がない。\n",
      "誰、、、、、、、、、、、、、、、、、、、。\n",
      "\n",
      "that 's just standard practise , it 's not like they 're cutting corners .\n",
      "それは定石通りというだけで、手を抜いたわけではないのです。\n",
      "そのののをを。。。\n",
      "\n",
      "until manet painted this picture , his female nudes were limited to goddesses .\n",
      "マネがこの絵を描くまで、女性の裸像は女神に限られていました。\n",
      "そのははのは。。。\n",
      "\n",
      "thinking about those sorts of things , i watched \" duck soup \" again .\n",
      "そんなことを考えながら『我輩はカモである』を再見しました。\n",
      "そのははははは。。。\n",
      "\n",
      "for a display where the data items increase and decrease i think you are best making use of a spreadsheet program , not access .\n",
      "項目が増えたり減ったりする表示なら、Accessでなくて表計算ソフトを活用すべきだと思います。\n",
      "またははは。。。\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/projects/jadlg_rnn/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "produce_out(val_dl,seq2seq,int2en,int2j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math,random\n",
    "\n",
    "def rand_t(*sz): return torch.randn(sz)/math.sqrt(sz[0])\n",
    "def rand_p(*sz): return nn.Parameter(rand_t(*sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAttention(nn.Module):\n",
    "    def __init__(self,en_vecs,int2en,j_vecs,int2j,em_sz,nh=128,out_sl=25,dropf=1,nl=2):\n",
    "        super().__init__()\n",
    "        #encoder\n",
    "        self.nl,self.nh,self.em_sz,self.out_sl = nl,nh,em_sz,out_sl\n",
    "        self.emb_enc = create_emb(en_vecs,int2en,dim_en_vec)\n",
    "        self.emb_drop = nn.Dropout(0.15*dropf)\n",
    "        self.encoder = nn.GRU(dim_en_vec,nh,num_layers=nl,dropout=0.25*dropf, bidirectional=True)\n",
    "        #decoder\n",
    "        self.emb_dec = create_emb(j_vecs,int2j,dim_j_vec)\n",
    "        self.decoder = nn.GRU(dim_en_vec,nh*2,num_layers=nl,dropout=0.25*dropf)\n",
    "        self.out_drop = nn.Dropout(0.35*dropf)\n",
    "        self.out = nn.Linear(nh*2,len(int2j))\n",
    "        #attention layer\n",
    "        self.W1 = rand_p(nh*2, nh*2) #parameter\n",
    "        self.l2 = nn.Linear(nh*2, nh*2)\n",
    "        self.l3 = nn.Linear(dim_en_vec+nh*2, dim_en_vec)\n",
    "        self.V = rand_p(nh*2) #parameter\n",
    "    \n",
    "    def forward(self,inp,y=None):\n",
    "        sl, bs = inp.size()\n",
    "        emb_in = self.emb_drop(self.emb_enc(inp))\n",
    "        h_n = self.initHidden(bs)\n",
    "        enc_out, h_n = self.encoder(emb_in,h_n)\n",
    "        h_n = h_n.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(self.nl,bs,-1)\n",
    "        \n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        #multiply by parameter\n",
    "        w1e = enc_out @ self.W1\n",
    "        for i in range(self.out_sl):\n",
    "            #linear layer\n",
    "            w2h = self.l2(h_n[-1])\n",
    "            #non-linear activation\n",
    "            u = torch.tanh(w1e + w2h)\n",
    "            #multiply by parameter\n",
    "            a = F.softmax(u @ self.V, 0)\n",
    "            ##multiply by parameter\n",
    "            Xa = (a.unsqueeze(2) * enc_out).sum(0)\n",
    "            dec_emb = self.emb_dec(dec_inp)\n",
    "            #linear layer\n",
    "            wgt_enc = self.l3(torch.cat([dec_emb, Xa], 1))\n",
    "            outp,h_n = self.decoder(wgt_enc.unsqueeze(0),h_n)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = outp.data.max(1)[1]\n",
    "            if (random.random() > 0.5) and y is not None: dec_inp=y[i] \n",
    "            if (dec_inp==1).all(): break\n",
    "        return torch.stack(res)\n",
    "        \n",
    "    def initHidden(self,bs):\n",
    "        return V(torch.zeros([self.nl*2,bs,self.nh]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unknowns in data: 974\n",
      "Number of unknowns in data: 492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2SeqAttention(\n",
       "  (emb_enc): Embedding(21393, 300, padding_idx=1)\n",
       "  (emb_drop): Dropout(p=0.15)\n",
       "  (encoder): GRU(300, 128, num_layers=2, dropout=0.25, bidirectional=True)\n",
       "  (emb_dec): Embedding(31813, 300, padding_idx=1)\n",
       "  (decoder): GRU(300, 256, num_layers=2, dropout=0.25)\n",
       "  (out_drop): Dropout(p=0.35)\n",
       "  (out): Linear(in_features=256, out_features=31813, bias=True)\n",
       "  (l2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (l3): Linear(in_features=556, out_features=300, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq = Seq2SeqAttention(en_vecs,int2en,j_vecs,int2j,dim_en_vec)\n",
    "seq2seq.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(seq2seq.parameters(),lr=3e-3,betas=(0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1124/1124 [04:13<00:00,  5.16it/s]\n",
      "  0%|          | 0/1124 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 trn loss: 7.638076941313693 val loss: 7.885180950164795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1124/1124 [04:22<00:00,  5.01it/s]\n",
      "  0%|          | 0/1124 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 trn loss: 7.432089324947778 val loss: 7.711851119995117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1124/1124 [04:22<00:00,  4.91it/s]\n",
      "  0%|          | 0/1124 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 trn loss: 7.407120456899188 val loss: 7.721337795257568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1124/1124 [04:21<00:00,  5.16it/s]\n",
      "  0%|          | 0/1124 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 trn loss: 7.410874541968213 val loss: 7.796937465667725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1124/1124 [04:24<00:00,  5.12it/s]\n",
      "  0%|          | 0/1124 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 trn loss: 7.417057778063194 val loss: 7.853030681610107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1124/1124 [04:24<00:00,  4.79it/s]\n",
      "  0%|          | 0/1124 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 trn loss: 7.416791848440612 val loss: 7.804213523864746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1124/1124 [04:20<00:00,  4.89it/s]\n",
      "  0%|          | 0/1124 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 trn loss: 7.417439313970003 val loss: 7.706363201141357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1124/1124 [04:21<00:00,  5.07it/s]\n",
      "  0%|          | 0/1124 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 trn loss: 7.417343817147496 val loss: 7.669027328491211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1124/1124 [04:21<00:00,  5.13it/s]\n",
      "  0%|          | 0/1124 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 trn loss: 7.42836168567481 val loss: 7.68925142288208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 92/1124 [00:21<04:01,  4.28it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-463aac38661c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2seq_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-0da3d8bb7530>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trn_dl, val_dl, model, crit, opt, epochs, clip)\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcrit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0mloss_trn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-16c1c05ec707>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(x, y, epoch, m, crit, opt, clip)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/jadlg_rnn/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/jadlg_rnn/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(trn_dl,val_dl,seq2seq,seq2seq_loss,opt,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the contents of the four registers are preserved by the called subroutine .\n",
      "4つのレジスタは、呼び出された関数側が保存する。\n",
      "、、、、、、、、、、、、、ののか、、\n",
      "\n",
      "that was when i was in the first year at high school , so 17 years have passed since then .\n",
      "それが高1の時だから17年が経ちました。\n",
      "は\n",
      "\n",
      "the siren sounded an emergency .\n",
      "サイレンが急変を知らせました。\n",
      "ははがが。\n",
      "\n",
      "the daughter was irritated with her mother , who always broke her promises .\n",
      "娘はいつも、約束を守らない母親に苛立っていた。\n",
      "１０に、をををているのををているのです。\n",
      "\n",
      "however the disciples awoke to that danger .\n",
      "しかし、使徒たちはその危険に気付いた。\n",
      "ははののでは、ののををているのだ。\n",
      "\n",
      "no consideration is paid to people who are sensitive to chemicals .\n",
      "化学物質に敏感な人々への配慮がない。\n",
      "人ががているのををするのは、のはををている。\n",
      "\n",
      "that 's just standard practise , it 's not like they 're cutting corners .\n",
      "それは定石通りというだけで、手を抜いたわけではないのです。\n",
      "、、、にに、、、、、、、、、、、、、、、、、、、\n",
      "\n",
      "until manet painted this picture , his female nudes were limited to goddesses .\n",
      "マネがこの絵を描くまで、女性の裸像は女神に限られていました。\n",
      "、、にに、、、、、、、、、、、、、、、、、、、、\n",
      "\n",
      "thinking about those sorts of things , i watched \" duck soup \" again .\n",
      "そんなことを考えながら『我輩はカモである』を再見しました。\n",
      "ははをををているのををている。\n",
      "\n",
      "for a display where the data items increase and decrease i think you are best making use of a spreadsheet program , not access .\n",
      "項目が増えたり減ったりする表示なら、Accessでなくて表計算ソフトを活用すべきだと思います。\n",
      "、は、、、をしているのは、、ををしているののです。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "produce_out(val_dl,seq2seq,int2en,int2j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
